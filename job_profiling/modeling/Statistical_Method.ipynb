{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711eebe0-bedf-48ae-92fc-507cd37fabbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "\n",
    "figure(figsize=(50,40), dpi=300)\n",
    "plt.rcParams[\"figure.figsize\"] = (50,40)\n",
    "\n",
    "\n",
    "from lifelines import KaplanMeierFitter, NelsonAalenFitter\n",
    "from sklearn.cluster import KMeans\n",
    "import datetime as dt\n",
    "import re, os, random\n",
    "import joblib, glob\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import graphviz \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "\n",
    "from sksurv.tree import SurvivalTree\n",
    "from sksurv.util import Surv\n",
    "from tree_exporter import plot_tree\n",
    "from sklearn import tree\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from scipy.stats import skew, kurtosis, entropy\n",
    "\n",
    "\n",
    "np.random.seed(122)\n",
    "random.seed(122)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf78276-f585-4929-ae99-9fea52b5527d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def survive(data, duration, event, fitter='kaplan'):\n",
    "    kmf = KaplanMeierFitter() if fitter == 'kaplan' else NelsonAalenFitter()\n",
    "    kmf.fit(durations=data[duration], event_observed=data[event])\n",
    "    print(kmf.event_table)\n",
    "    return kmf, kmf.durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125fc6dd-8790-4491-8ca4-e59fd08cab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    feature_names = [f.replace(\" \", \"_\")[:-5] for f in feature_names]\n",
    "    print(\"def predict({}):\".format(\", \".join(feature_names)))\n",
    "    count = 0\n",
    "    def recurse(node, depth):\n",
    "        indent = \"|    \" * depth\n",
    "        nonlocal count\n",
    "        count += 1\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print(\"{}if {} <= {}:\".format(indent, name, np.round(threshold,2)))\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print(\"{}else:  # if {} > {}\".format(indent, name, np.round(threshold,2)))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print(\"{}return {} \".format(indent, tree_.n_node_samples[node]), '->', count - 1)\n",
    "\n",
    "    recurse(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb03e334-77ce-43b6-91e6-effd6c0c7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dendrogram(model, **kwargs):\n",
    "    # Create linkage matrix and then plot the dendrogram\n",
    "\n",
    "    # create the counts of samples under each node\n",
    "    counts = np.zeros(model.children_.shape[0])\n",
    "    n_samples = len(model.labels_)\n",
    "    for i, merge in enumerate(model.children_):\n",
    "        current_count = 0\n",
    "        for child_idx in merge:\n",
    "            if child_idx < n_samples:\n",
    "                current_count += 1  # leaf node\n",
    "            else:\n",
    "                current_count += counts[child_idx - n_samples]\n",
    "        counts[i] = current_count\n",
    "\n",
    "    linkage_matrix = np.column_stack(\n",
    "        [model.children_, model.distances_, counts]\n",
    "    ).astype(float)\n",
    "\n",
    "    # Plot the corresponding dendrogram\n",
    "    shc.dendrogram(linkage_matrix, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd6e5ce-f177-41ac-a614-c32311aa6330",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predect_node_for_missing_value(model, data): # this is a brute force solution. I beleive there is a better one can be found\n",
    "    \"\"\"This function build the tree structure then select a node for it iff it has missing values \"\"\"\n",
    "    if any(elem is None for elem in data) or any(elem is np.nan for elem in data):\n",
    "        pass\n",
    "    else: \n",
    "        return 0, \"This person doesn't have any missing values\"\n",
    "    \n",
    "    n_nodes = model.tree_.node_count\n",
    "    children_left = model.tree_.children_left\n",
    "    children_right = model.tree_.children_right\n",
    "    feature = model.tree_.feature\n",
    "    name = model.feature_names_in_\n",
    "    threshold = model.tree_.threshold\n",
    "    samples = model.tree_.n_node_samples\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    print( \"The binary tree structure has {n} nodes, {l} leaves and has the following tree structure:\\n\".format(n=n_nodes, l=np.sum(is_leaves)))\n",
    "    \n",
    "    current_node = 0\n",
    "    for i in range(n_nodes):\n",
    "        print('current_node is', current_node, end=' ::: ')\n",
    "        if is_leaves[i]:\n",
    "            print(\"{space}node={node} is a leaf node.\".format(space=node_depth[i] * \"\\t\", node=i))\n",
    "        else:\n",
    "            if data[feature[i]] is np.nan or data[feature[i]] is None:\n",
    "                if current_node == i:\n",
    "                    print(f\"{node_depth[i] * '    '}node={i} is a split node: go to node {children_left[i]} if node {children_left[i]} counts {samples[children_left[i]]} >= node{children_right[i]} counts{samples[children_right[i]]} else to node {children_right[i]}.\")\n",
    "                    if samples[children_left[i]] >= samples[children_right[i]]:\n",
    "                        current_node = children_left[i]\n",
    "                    elif samples[children_right[i]] > samples[children_left[i]]:\n",
    "                        current_node = children_right[i]\n",
    "            else:\n",
    "                if current_node == i:\n",
    "                    print(f\"{node_depth[i] * '    '}node={i} is a split node: go to node {children_left[i]} if X[:, {feature[i]} {name[feature[i]]}] <= {threshold[i]} else to node {children_right[i]}.\")\n",
    "                    if data[feature[i]] <= threshold[i]:\n",
    "                        current_node = children_left[i]\n",
    "                        \n",
    "                    elif data[feature[i]] > threshold[i]:\n",
    "                        current_node = children_right[i]\n",
    "        \n",
    "        if is_leaves[current_node]:\n",
    "            print(f'Node {current_node} is a leaf node. Its the node where this person will land')\n",
    "            return current_node, np.argmax(model.tree_.value[current_node])\n",
    "        \n",
    "    return current_node, np.argmax(model.tree_.value[current_node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b1aee0-a8d6-4807-81be-4e961ec71847",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHOD1 = 'METHOD1'\n",
    "METHOD2 = 'METHOD2'\n",
    "METHOD3 = 'METHOD3'\n",
    "MALE = 'male'\n",
    "FEMALE = 'female'\n",
    "CONTRIBUTORS = 'CONTRIBUTORS'\n",
    "TARGET = 'TARGET'\n",
    "MODEL = 'model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ba978d-ba13-4930-b8ed-e16cc5fb1caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = 'national_id_number'\n",
    "LAST_JOB = 'last_job_c'\n",
    "FIRST_JOB = 'first_job'\n",
    "EXPERIENCE = 'experience'\n",
    "AGE = 'age'\n",
    "GOVERNORATE = 'governorate'\n",
    "DISABILITY = 'disability'\n",
    "GENDER = 'gender'\n",
    "EDUCATION = 'education'\n",
    "UNEMPLOYMENT_YAER = 'unemployment_year'\n",
    "SAME_JOB = 'same_job'\n",
    "WAGE = 'wage_adj_c'\n",
    "POVERTY = 'poverty'\n",
    "INDUSTRY = 'industry'\n",
    "SPELL = 'unemployment_spell'\n",
    "# EMPLOYMENT = 'employment'\n",
    "\n",
    "\n",
    "NODES = 'nodes'\n",
    "CLUSTER = 'clusters'\n",
    "DURATIONS = 'durations'\n",
    "NODES_DESTRO = 'nodes_destros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45a6db-8fca-4608-ad0d-753c0268f47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIGINAL_COLUMNS = ['NationalID_Number', 'LastJobC' ,'FirstJob', 'experience', 'age', 'Governorate','Disability', 'Gender', 'education','UnemploymentYear','SameJob', 'wage_adj_c','Poverty', 'Industry','UnemploymentSpell']\n",
    "PROCESSED_COLUMNS = [ID, LAST_JOB, FIRST_JOB, EXPERIENCE, AGE, GOVERNORATE, DISABILITY, GENDER, EDUCATION, UNEMPLOYMENT_YAER, SAME_JOB, WAGE, POVERTY, INDUSTRY, SPELL]\n",
    "\n",
    "ATTRIBUTES = [EXPERIENCE, AGE, GOVERNORATE, DISABILITY, EDUCATION, GENDER]\n",
    "\n",
    "ONE_HOT_ENCODED_FEATURES = [GOVERNORATE, EDUCATION,] #  EXPERIENCE, AGE, \n",
    "LABEL_ENCODED_FEATURES = [GENDER, DISABILITY]\n",
    "\n",
    "ENCODERS = {}\n",
    "API_ENCODERS = {}\n",
    "\n",
    "MAX_NODES_COUNT = None\n",
    "#################################################################### LAST MODIFY 600 --> 50\n",
    "# MINIMUM_LEAF_COUNT = 150\n",
    "MINIMUM_LEAF_COUNT = 200\n",
    "MINIMUM_DURATION_CUT = 60\n",
    "MAXIMUM_DURATION_CUT = 1800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74da6f2-8245-4f23-bb03-42be53995f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "METHODS = {\n",
    "    METHOD1:{\n",
    "        CONTRIBUTORS: [EXPERIENCE, AGE, GOVERNORATE, DISABILITY, EDUCATION, INDUSTRY,],\n",
    "        TARGET:f'{SPELL}',\n",
    "        MODEL:'DecisionTreeRegressor()'\n",
    "    },\n",
    "    METHOD2:{\n",
    "        CONTRIBUTORS: [EXPERIENCE, AGE, GOVERNORATE, DISABILITY, EDUCATION, INDUSTRY,],\n",
    "        TARGET:f\"Surv.from_dataframe({LAST_JOB}, {SPELL},\" + \" {0})\",\n",
    "        MODEL:f'SurvivalTree(min_samples_leaf={MINIMUM_LEAF_COUNT})' \n",
    "    },\n",
    "    METHOD3:{\n",
    "        CONTRIBUTORS: [EXPERIENCE, AGE, GOVERNORATE, DISABILITY, EDUCATION,],\n",
    "        TARGET:f\"Surv.from_dataframe('{LAST_JOB}', '{SPELL}',\" + \" {0})\",\n",
    "        # MODEL:f'SurvivalTree(min_samples_leaf={MINIMUM_LEAF_COUNT}, max_leaf_nodes={MAX_NODES_COUNT})'\n",
    "        MODEL:f'SurvivalTree(min_samples_leaf={MINIMUM_LEAF_COUNT}, )'\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72746a0e-c317-40d1-8335-0a5b7bce53aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INPUT_PATH = os.path.join('.','data','Unemployment Data.dta')\n",
    "DATA_OUTPUT_PATH = os.path.join('.','data','final_outputs.csv')\n",
    "MODELS_OUTPUT_PATH = os.path.join('.','runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a67abd-c31b-4a2f-a69f-21f3b6c092fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_stata(DATA_INPUT_PATH) # [['experience', 'Governorate', 'Name_tr', 'Disabled_tr', 'EducationalAttainment', 'JobSeekers_DateOfBirth', 'job_search_start']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0924fdae-788a-41f7-8b15-808c60e52895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.NationalID_Number = df.NationalID_Number.astype(str)\n",
    "max_date = df.end_date.max()\n",
    "con = np.logical_and(\n",
    "    df.NationalID_Number == df.groupby(['NationalID_Number'])['NationalID_Number'].shift(1),\n",
    "    df.reason_suspension_tr.isin(['Resignation', 'Laid off'])\n",
    ")\n",
    "df['RegisterAfterFired'] = np.where(con, 1, 0)\n",
    "# NEEDS MORE ATTINTION\n",
    "if 'METHOD3' == METHOD3:\n",
    "    con = np.logical_and(\n",
    "        df.last_ind == 1,\n",
    "        df.reason_suspension_tr.isin(['Resignation', 'Laid off'])\n",
    "    )\n",
    "    df['LastJobC'] = np.where(con, 0, 1)\n",
    "    \n",
    "    # data$LastJobC[data$`_merge_with_mol`==2]         = 0\n",
    "    # data$experience[data$`_merge_with_mol`==2]       = 0\n",
    "    # data$end_date[data$`_merge_with_mol`==2]         = data$RegistrationdateintoNEES[data$`_merge_with_mol`==2]\n",
    "    # data$econ_activity_tr[data$`_merge_with_mol`==2] = ''\n",
    "    \n",
    "    df_temp = df[df.last_ind == 1]\n",
    "    # data$LastJobC               = 1\n",
    "    df_temp.unempl_spell = pd.to_datetime(max_date) - pd.to_datetime(df_temp.end_date)\n",
    "    df_temp.RegisterAfterFired = 1\n",
    "    \n",
    "    # data= rbind(data,dataTemp)  # this will create duplicate\n",
    "df['validCase'] = np.where(df.first_ind == 1, 1, df.RegisterAfterFired)\n",
    "con = np.logical_and(\n",
    "    df.validCase == 1,\n",
    "    np.logical_not(df.econ_activity_tr.isin(['Public administration, defense, and social security']))\n",
    ")\n",
    "df1 = df[con]\n",
    "df1 = df1.dropna(subset=['unempl_spell'])\n",
    "con = np.logical_and(\n",
    "    df1.unempl_spell > MINIMUM_DURATION_CUT,\n",
    "    df1.unempl_spell < MAXIMUM_DURATION_CUT,\n",
    ")\n",
    "df1 = df1[con]\n",
    "df1.info() # this only what left after filtaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a4f299-5729-461e-bd18-459d299f2179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def experience_code(value):\n",
    "    if value > 15:\n",
    "        return 20\n",
    "    elif value > 10:\n",
    "        return 15\n",
    "    elif value > 5:\n",
    "        return 10\n",
    "    elif value > 1:\n",
    "        return 5\n",
    "    elif value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "\n",
    "# - Dummy for first job:\n",
    "df1['FirstJob'] = np.where(df1.first_ind == 1, 1, 0)\n",
    "\n",
    "# #  - Experience:\n",
    "df1.experience = np.round(df1.experience / 365)\n",
    "df1.experience = df1.experience.apply(experience_code)\n",
    "\n",
    "# - Age:\n",
    "df1['age'] = (df1.job_search_start - dt.datetime(1970, 1, 1)).dt.total_seconds().astype(int) - (df1.JobSeekers_DateOfBirth - dt.datetime(1970, 1, 1)).dt.total_seconds().astype(int)\n",
    "df1['age'] = (np.round((df1['age'] / (60 * 60 * 24 * 365)) / 10) * 10).astype(int)\n",
    "\n",
    "# - Governorate:\n",
    "df1.Governorate = df1.Governorate.str.lower()\n",
    "\n",
    "# - Disability:\n",
    "df1['Disability'] = df1.Disabled_tr.str.lower()\n",
    "\n",
    "# - Gender:\n",
    "df1['Gender'] = df1.Name_tr.str.lower()\n",
    "\n",
    "\n",
    "# - Education Level:\n",
    "df1.EducationalAttainment[df1.EducationalAttainment.isin([\"High Diploma\", \"Bachelor\", \"Masters\", \"PhD\"])] = 'bachelor_or_above'\n",
    "df1.EducationalAttainment[df1.EducationalAttainment.isin([\"Vocational Training\"])] = \"Vocational Training\"\n",
    "df1.EducationalAttainment[df1.EducationalAttainment.isin([\"Middle Diploma\"])] = \"Middle Diploma\"\n",
    "df1.EducationalAttainment[df1.EducationalAttainment.isin([\"Secondary or Below\"])] = \"Secondary or Below\"\n",
    "df1 = df1.rename(columns = {'EducationalAttainment':'education'})\n",
    "\n",
    "# - Year of unemployment:\n",
    "df1['UnemploymentYear'] = 0\n",
    "\n",
    "\n",
    "# - Same Job:\n",
    "df1['SameJob'] = np.where(df1.rep_job == 1, 'Yes', 'No')\n",
    "\n",
    "# - Poverty:\n",
    "df1['Poverty'] =  df1.poverty_score.fillna(0)\n",
    "\n",
    "# - Industry:\n",
    "df1['Industry'] = df1.econ_activity_tr.str.lower()\n",
    "if('METHOD2' == METHOD2): \n",
    "    df1['Industry'] =  df1['Industry'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "\n",
    "# - Unemployment Spell:\n",
    "df1['UnemploymentSpell'] = df1.unempl_spell / 30 # Measured in months.\n",
    "\n",
    "\n",
    "# - Wages:\n",
    "df1['wage_adj_c'] = df1[['wage_adj']].fillna(-1000).astype(np.int)\n",
    "t = KMeans(n_clusters=4, init='k-means++', n_init=10).fit(df1[['wage_adj_c']])\n",
    "# clustered_data = t.fit_transform(df1[['wage_adj_c']])\n",
    "df1['wage_adj_c'] = df1[['wage_adj_c']].groupby(t.labels_).transform('mean').sum(1).rank(method='dense').sub(1).astype(np.int64).to_frame()\n",
    "# clusters_mean = []\n",
    "# for i in range(t.n_clusters):\n",
    "#     clusters_mean.append(clustered_data[:, i].mean())\n",
    "#     print(clusters_mean)\n",
    "\n",
    "print(df1.info())\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f04da52-c1d7-4e55-994c-905dfc08d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in ORIGINAL_COLUMNS:\n",
    "#     if i not in list(df1.columns):\n",
    "#         print(i)\n",
    "fdf = df1[ORIGINAL_COLUMNS].dropna()\n",
    "\n",
    "#################################################################### LAST MODIFY\n",
    "# con = np.logical_and(\n",
    "#     fdf.Governorate != 'zarqa',\n",
    "#     np.logical_and(\n",
    "#         fdf.Governorate != 'amman',\n",
    "#         fdf.Governorate != 'irbid',\n",
    "#     )\n",
    "# )\n",
    "# fdf.loc[con, 'Governorate'] = 'other'\n",
    "\n",
    "\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     fdf.education != 'Secondary or Below',\n",
    "#     fdf.education != 'bachelor_or_above',\n",
    "# )\n",
    "# fdf.loc[con, 'education'] = 'other'\n",
    "####################################################################\n",
    "\n",
    "\n",
    "print(fdf.info())\n",
    "print('-' * 100)\n",
    "for col in fdf.columns:\n",
    "    print(col, '----------->', len(fdf[col].unique()))\n",
    "    print(fdf[col].unique(), '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87347e5-d147-452e-b93a-ed23d090c5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unify_column_names(df):\n",
    "    cols = []\n",
    "    for col in df.columns:\n",
    "        col = re.sub(r\"(\\w)([A-Z])\", r\"\\1 \\2\", col)\n",
    "        cols.append(col.strip(' .()[]{}/\\#@*^!?').replace('_', ' ').replace(' ', '_').replace(',', '_').replace('__', '_').lower())\n",
    "    df.columns = cols\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_string_data(df):\n",
    "    # unify dealing with strings data\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        df[col] = df[col].str.replace(' ', '_')\n",
    "        df[col] = df[col].str.replace('-', '_')\n",
    "        df[col] = df[col].str.replace(',', '_')\n",
    "        df[col] = df[col].str.replace('__', '_').str.lower()\n",
    "    return df\n",
    "\n",
    "def build_encoders(df, encoder_dict, save=False, label_encoded=LABEL_ENCODED_FEATURES, one_hot_encoded=ONE_HOT_ENCODED_FEATURES):\n",
    "    for col in df.select_dtypes(include=['object']):\n",
    "        if col in one_hot_encoded:\n",
    "            \n",
    "            encoder = OneHotEncoder(sparse=False)\n",
    "            temp = pd.DataFrame(\n",
    "                encoder.fit_transform(df[[col]]),\n",
    "                columns=list(encoder.get_feature_names_out())\n",
    "            )\n",
    "            df = pd.concat([df, temp], axis=1).drop(col, axis=1)\n",
    "\n",
    "        elif col in label_encoded:\n",
    "            encoder = LabelEncoder()\n",
    "            df[col] = encoder.fit_transform(df[col])\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"'{col}' can't be encoded.\")\n",
    "        \n",
    "        if save:\n",
    "            encoder_dict[col] = encoder\n",
    "    #     print(col)\n",
    "    #     print(df.head())\n",
    "    #     print('-'*100, 'Next Item')\n",
    "    return df\n",
    "    \n",
    "def advanced_processing(data, encode=False, save=False):\n",
    "    data = data.replace(r'^\\s*$', np.nan, regex=True).dropna() # drop any record with nulls\n",
    "    data = data.reset_index(drop=True)\n",
    "\n",
    "    data = format_string_data(unify_column_names(data))\n",
    "    print(data.info())\n",
    "    \n",
    "    data = data.reset_index(drop=True)\n",
    "    if encode:\n",
    "        data = build_encoders(data, ENCODERS, save=save)\n",
    "        print(data.info())\n",
    "        \n",
    "    return data\n",
    "\n",
    "\n",
    "fdf = unify_column_names(fdf)\n",
    "fdf.drop(fdf[fdf[SPELL].isnull()].index, inplace=True)\n",
    "fdf\n",
    "\n",
    "# data = fdf.replace(r'^\\s*$', np.nan, regex=True).dropna() # drop any record with nulls\n",
    "# print(data.info())\n",
    "# data = unify_column_names(data)\n",
    "# print(data.info())\n",
    "# data = format_string_data(data)\n",
    "# print(data.info())\n",
    "# data = data.reset_index(drop=True)\n",
    "# print(data.info())\n",
    "# build_encoders(data[METHODS[METHOD3][CONTRIBUTORS]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb53ecef-ae52-4e24-82b1-6c4cf85cd095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c36dc9e-1aeb-43dd-9be4-cf4179e7d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_predict(X, y, method=METHOD3):\n",
    "    print(X.shape, y.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "    # for i in range(2, len(X.columns)):\n",
    "    #     print(\"-\"*80, i, '-'*80)\n",
    "    model = eval(METHODS[method][MODEL])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    print('Accuracy for training:',model.score(X_train, y_train))\n",
    "    print('Accuracy for testing:',model.score(X_test, y_test))\n",
    "    return model #, graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1faa2f-f2f3-4000-b191-892563da960b",
   "metadata": {},
   "outputs": [],
   "source": [
    "advanced_processing(fdf[ATTRIBUTES], encode=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce529fb-572c-4563-9948-e5e717a6c86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_aggre(data):\n",
    "    data = data.copy()\n",
    "    data.columns = data.columns.droplevel()\n",
    "    display(data)\n",
    "    for col in data.columns:\n",
    "        data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "    # x = data.transpose()#.reset_index(drop=True)\n",
    "    # return ((x - x.mean()) / x.std()).transpose()\n",
    "    # return (data - data.mean()) / data.std()\n",
    "    # return (data - data.mean()) / data.std()\n",
    "    return data\n",
    "\n",
    "# def swap(a, target):\n",
    "#     return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021593eb-9b2e-433c-b398-77ec2b68fd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODES_APPLY = 'nodes_apply'\n",
    "genders = [MALE, FEMALE]\n",
    "methods = [METHOD3] # METHOD1, METHOD2,\n",
    "\n",
    "per25 = lambda x: pd.Series(x, name='p25').quantile(0.25)\n",
    "per75 = lambda x: pd.Series(x, name='p25').quantile(0.75)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(DATA_OUTPUT_PATH):\n",
    "    os.remove(DATA_OUTPUT_PATH)\n",
    "\n",
    "for gen in genders:\n",
    "    for method in methods:\n",
    "        temp = advanced_processing(fdf[fdf[GENDER] == gen][METHODS[method][CONTRIBUTORS]], encode=False).reset_index(drop=True)\n",
    "        data = advanced_processing(fdf[fdf[GENDER] == gen][METHODS[method][CONTRIBUTORS]], encode=True,).reset_index(drop=True)\n",
    "        # display(data)\n",
    "        \n",
    "        target = eval(METHODS[method][TARGET].format('fdf[fdf[GENDER] == gen]')) if '(' in METHODS[method][TARGET] else METHODS[method][TARGET]\n",
    "        \n",
    "        print(len(target))\n",
    "\n",
    "        model = build_and_predict(X=data, y=target, )\n",
    "        print(\"The total number of leafs is:\",  model.tree_.n_leaves)\n",
    "        print(\"Avg count per leaf:\", np.mean(model.tree_.n_node_samples))\n",
    "        \n",
    "        print('-'*150 )\n",
    "        print('Tree Rules...')\n",
    "        print(tree_to_code(model, model.feature_names_in_))\n",
    "        print('-'*150 )\n",
    "        \n",
    "        graph = plot_tree(\n",
    "            model,\n",
    "            feature_names=model.feature_names_in_,\n",
    "            impurity=False,\n",
    "            label=\"all\",\n",
    "            fontsize=20,\n",
    "            filled=True,\n",
    "            # proportion=True,\n",
    "            node_ids=True, \n",
    "            class_names=['0', '1', '2'],\n",
    "        )\n",
    "        \n",
    "        joblib.dump(model, os.path.join(MODELS_OUTPUT_PATH, f'{gen}_surv_tree_model.joblib'))\n",
    "        \n",
    "        ############## This is last modify, it is a replacment for the predict, it will output the node directly instead of the node_distro ##############\n",
    "        data[NODES] = model.tree_.apply(data.to_numpy().astype('float32')) \n",
    "        \n",
    "        \n",
    "        # data[NODES_DESTRO] = np.round(model.predict(data), decimals=8).astype(object)\n",
    "        # display(data[NODES_DESTRO])\n",
    "        \n",
    "        # encoder = LabelEncoder()\n",
    "        # data[NODES] = encoder.fit_transform(data[NODES_DESTRO])\n",
    "        # data[NODES_DESTRO] = data[NODES_DESTRO].astype(np.float32)\n",
    "        \n",
    "        # ENCODERS[NODES] = encoder\n",
    "        # joblib.dump(encoder,  os.path.join(MODELS_OUTPUT_PATH, f'{gen}_surv_tree_nodes_encoder.joblib'))\n",
    "        \n",
    "\n",
    "    data[SPELL] = fdf[fdf[GENDER] == gen][SPELL].reset_index(drop=True)\n",
    "    data[LAST_JOB] = fdf[fdf[GENDER] == gen][LAST_JOB].reset_index(drop=True)\n",
    "    # display(data)\n",
    "        \n",
    "    data[DURATIONS] = survive(fdf[fdf[GENDER] == gen].drop(GENDER, axis=1), duration=SPELL, event=LAST_JOB)[-1] \n",
    "    data.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    \n",
    "    aggregated_df = data[[SPELL, NODES]].groupby(NODES).agg([np.min, np.median, np.std, np.max, np.mean, kurtosis, skew, entropy, per25, per75]) \n",
    "    aggregated_df = scale_aggre(aggregated_df) ############################### did not give the hoped results\n",
    "    # display(aggregated_df)\n",
    "        \n",
    "    cluster = AgglomerativeClustering(n_clusters=3, affinity='euclidean', linkage='ward', compute_full_tree=True, compute_distances=True,)\n",
    "    aggregated_df[CLUSTER] = cluster.fit_predict(aggregated_df)\n",
    "    display(aggregated_df)\n",
    "    \n",
    "    \n",
    "    # joblib.dump(cluster, os.path.join(MODELS_OUTPUT_PATH, f'{gen}_ward_clustering_model.joblib'))\n",
    "    aggregated_df.to_csv(os.path.join(MODELS_OUTPUT_PATH, f'{gen}_ward_clustering_data.csv'))\n",
    "    \n",
    "    plt.figure(figsize=(15, 9))\n",
    "    plot_dendrogram(cluster, truncate_mode='lastp', distance_sort=True)\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    dd = {node:cluster for node, cluster in zip(aggregated_df.index, aggregated_df[CLUSTER].to_numpy()) } # aggregated_df.index is the tree correct nodes\n",
    "    data[CLUSTER] = data[NODES].map(dd)\n",
    "    print(dd)\n",
    "    joblib.dump(dd, os.path.join(MODELS_OUTPUT_PATH, f'{gen}_cluster_node_dict_mapper.joblib'))\n",
    "    \n",
    "    corector = data[[SPELL, CLUSTER]].groupby(CLUSTER).mean()\n",
    "    print('Clusters mean durations before mapping', corector)\n",
    "\n",
    "    order = pd.Series(dict((v,k) for k,v in np.argsort(corector[SPELL]).sort_values().iteritems())).to_dict()\n",
    "    joblib.dump(order, os.path.join(MODELS_OUTPUT_PATH, f'{gen}_cluster_node_dict_cmapper_x.joblib'))\n",
    "    print(order)\n",
    "\n",
    "    data[CLUSTER] = data[CLUSTER].map(order)\n",
    "    print('Clusters mean durations after mapping:', data[[SPELL, CLUSTER]].groupby(CLUSTER).mean())  \n",
    "    print('Samples within each cluster:', data[CLUSTER].value_counts())\n",
    "    \n",
    "    temp[GENDER] = gen\n",
    "    temp[CLUSTER] = data[CLUSTER]\n",
    "    temp[NODES] = data[NODES]\n",
    "    temp[DURATIONS] = data[DURATIONS]\n",
    "    temp[SPELL] = data[SPELL]\n",
    "    temp[LAST_JOB] = data[LAST_JOB]\n",
    "    \n",
    "    if os.path.exists(DATA_OUTPUT_PATH):\n",
    "        temp.to_csv(DATA_OUTPUT_PATH, index=False, mode='a', header=False)\n",
    "    else:\n",
    "        temp.to_csv(DATA_OUTPUT_PATH, index=False, mode='a')\n",
    "    \n",
    "    plt.figure(figsize=(15, 9))\n",
    "    data[SPELL].hist(by=data[CLUSTER], bins=20, density=True, alpha=0.7, grid=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899de75-c3e1-4e3a-9a6b-f22802b3e7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ENCODERS)\n",
    "\n",
    "for enc in ENCODERS:\n",
    "    if enc == 'nodes':\n",
    "        continue\n",
    "    joblib.dump(ENCODERS[enc], os.path.join(MODELS_OUTPUT_PATH, f'{enc}_encoders.joblib') )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0d10c8-f376-4c37-bccd-783e57ce97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ae40d101-96b1-4f4e-943e-ef96f26516c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attributes and contributors\n",
    "GOVERNORATE = 'governorate'\n",
    "AGE = 'age'\n",
    "EXPERIENCE = 'experience'\n",
    "EDUCATION = 'education'\n",
    "GENDER = 'gender'\n",
    "DISABILITY = 'disability'\n",
    "\n",
    "# Integrity strings\n",
    "NA_FILL_VALUE = 'NA_FILL_VALUE'\n",
    "CATEGORIES = 'CATEGORIES'\n",
    "CODE = 'CODE'\n",
    "\n",
    "def disability_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    value = str(value).lower()\n",
    "    if value not in ['no_disability', 'nodisability', 'no', 'not_disabled']:\n",
    "        return 'with_disability'\n",
    "    return 'no_disability'\n",
    "\n",
    "\n",
    "def experience_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    value = float(value)\n",
    "    if value > 15:\n",
    "        return 20\n",
    "    elif value > 10:\n",
    "        return 15\n",
    "    elif value > 5:\n",
    "        return 10\n",
    "    elif value > 1:\n",
    "        return 5\n",
    "    elif value > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def age_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    \n",
    "    age = int(round(float(value) / 10) * 10)\n",
    "    if age > 60:\n",
    "        return 60\n",
    "    elif age < 20:\n",
    "        return 20\n",
    "    else:\n",
    "        return age\n",
    "\n",
    "\n",
    "\n",
    "def education_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    value = str(value).lower()\n",
    "    education_subs = {\n",
    "        'bachelor_or_above': [\n",
    "            'bachelor_or_above', 'bachelor', 'bachelors', \"bs\", \"b.s\", \"bas\",\n",
    "            'master', 'masters', 'm.s', 'ms', 'phd', 'doctor_of_philosophy', 'doctorate', 'doctorates'\n",
    "        ],\n",
    "        'vocational_training': [\n",
    "            \"vocational_training\", 'vt', 'v.t'\n",
    "        ],\n",
    "        'middle_diploma': [\n",
    "            \"middle_diploma\", 'diploma' \"high_diploma\", 'deploma', \"high_deploma\", \"middle_deploma\",\n",
    "        ],\n",
    "        'secondary_or_below': [\n",
    "            \"secondary_or_below\", 'high_school', 'school', 'secondary', 'secondary_school'\n",
    "        ],\n",
    "    }\n",
    "    for key in education_subs:\n",
    "        if value in education_subs[key]:\n",
    "            return key\n",
    "\n",
    "    return TEMPLATE_DATA_CATEGORIES[EDUCATION][NA_FILL_VALUE]\n",
    "\n",
    "\n",
    "def governorate_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    value = str(value).lower()  # .replace(f'governorate_', '')\n",
    "    governorate_subs = {\n",
    "        'al_kirk': ['al_kark', 'al_kirk', 'kark', 'kirk', ],\n",
    "        'balqa': ['balqa', 'al_balqa', 'balqaa', 'al_balqaa', ],\n",
    "        'tafileh': ['tafileh', 'al_tafileh', ],\n",
    "        'jarash': ['jarash', 'jerash'],\n",
    "        'zarqa': ['zarqa', 'al_zarqa'],\n",
    "        'amman': ['amman', 'aman'],\n",
    "        'al_mafraq': ['al_mafraq', 'mafraq'],\n",
    "        'maan': ['maan', ],\n",
    "        'irbid': ['irbid', 'irbed'],\n",
    "        'al_aqaba': ['al_aqaba', 'aqaba'],\n",
    "        'maadaba': ['maadaba', 'madaba'],\n",
    "        'ajloun': ['ajloun'],\n",
    "    }\n",
    "    for key in governorate_subs:\n",
    "        if value in governorate_subs[key]:\n",
    "            return key\n",
    "    return TEMPLATE_DATA_CATEGORIES[GOVERNORATE][NA_FILL_VALUE]\n",
    "\n",
    "\n",
    "def gender_code(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "\n",
    "    value = str(value).lower()\n",
    "    gender_subs = {\n",
    "        'male': ['male', 'm', 'man'],\n",
    "        'female': ['female', 'f', 'woman'],\n",
    "    }\n",
    "    for key in gender_subs:\n",
    "        if value in gender_subs[key]:\n",
    "            return key\n",
    "    return TEMPLATE_DATA_CATEGORIES[GENDER][NA_FILL_VALUE]\n",
    "\n",
    "\n",
    "TEMPLATE_DATA_CATEGORIES = {\n",
    "    DISABILITY: {\n",
    "        CATEGORIES: ['with_disability', 'no_disability'],\n",
    "        # CODE: \"utils.disability_code({0})\",\n",
    "        CODE: \"disability_code({0})\",\n",
    "        NA_FILL_VALUE: 'no_disability'\n",
    "    },\n",
    "    EXPERIENCE: {\n",
    "        CATEGORIES: [0, 1, 5, 10, 15, 20],\n",
    "        # CODE: \"utils.experience_code({0})\",\n",
    "        CODE: \"experience_code({0})\",\n",
    "        NA_FILL_VALUE: 0\n",
    "    },\n",
    "    AGE: {\n",
    "        CATEGORIES: [10, 20, 30, 40, 50, 60],\n",
    "        # CODE: \"utils.age_code({0})\",\n",
    "        CODE: \"age_code({0})\",\n",
    "        NA_FILL_VALUE: 30\n",
    "    },\n",
    "\n",
    "    EDUCATION: {\n",
    "        CATEGORIES: ['bachelor_or_above', 'vocational_training', 'middle_diploma', 'secondary_or_below'],\n",
    "        # CODE: \"utils.education_code({0})\",\n",
    "        CODE: \"education_code({0})\",\n",
    "        NA_FILL_VALUE: 'secondary_or_below'\n",
    "    },\n",
    "    GOVERNORATE: {\n",
    "        CATEGORIES: [\n",
    "            'ajloun', 'al_aqaba', 'al_kirk',\n",
    "            'al_mafraq', 'amman', 'balqa',\n",
    "            'irbid', 'jarash', 'maadaba',\n",
    "            'maan', 'tafileh', 'zarqa'\n",
    "        ],\n",
    "        # CODE: \"utils.governorate_code({0})\",\n",
    "        CODE: \"governorate_code({0})\",\n",
    "        NA_FILL_VALUE: 'amman'\n",
    "    },\n",
    "    GENDER: {\n",
    "        CATEGORIES: ['male', 'female'],\n",
    "        # CODE: \"utils.gender_code({0})\",\n",
    "        CODE: \"gender_code({0})\",\n",
    "        NA_FILL_VALUE: 'male'\n",
    "    },\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "def preprocess_recs(rec, cols_lst):\n",
    "    dct = {}\n",
    "    for column in cols_lst:\n",
    "        value = rec.get(column, None)\n",
    "        res = eval(TEMPLATE_DATA_CATEGORIES[column][CODE].format('value'))\n",
    "        dct[column] = res\n",
    "        \n",
    "    print('After preprocessing:', dct)\n",
    "    return dct\n",
    "\n",
    "\n",
    "def load_encoders(into = None, path=None):\n",
    "    into = into.copy() if into is not None else {}\n",
    "    \n",
    "    \n",
    "    if path is None:\n",
    "        path = os.path.join(MODELS_OUTPUT_PATH, f'*_encoders.joblib')\n",
    "        \n",
    "    for enc in glob.iglob(path):\n",
    "        name = enc.split('\\\\')[-1].split('_')[0]\n",
    "        into[name] = joblib.load(enc)\n",
    "        \n",
    "    print(\"Loaded encoders\", into)\n",
    "    return into\n",
    "        \n",
    "\n",
    "def encode_new_data(data, cols_lst, encoders, onehot_encoded, label_encoded):\n",
    "    model_input = {}\n",
    "    for feature in cols_lst:\n",
    "        value = data.get(feature, None)\n",
    "        # print(value)\n",
    "        if feature in label_encoded:\n",
    "            model_input[feature] = int(encoders[feature].transform([value])[0]) if value is not None else value\n",
    "\n",
    "        elif feature in onehot_encoded:\n",
    "            if value is not None:\n",
    "                item = encoders[feature].transform([[value]])[-1]\n",
    "                lst = {name: int(value) for name, value in zip(encoders[feature].get_feature_names_out(), item)}\n",
    "            else:\n",
    "                lst = {\n",
    "                    i: None for i in encoders[feature].get_feature_names_out()\n",
    "                }\n",
    "            model_input.update(lst)\n",
    "            \n",
    "        else:\n",
    "            model_input[feature] = int(value) if value is not None else value\n",
    "    return model_input\n",
    "    \n",
    "def reorder_cols(data_dct, order):\n",
    "    res = pd.DataFrame(data_dct, index=[0])[order]\n",
    "    if data_dct[GENDER] == 0 or data_dct[GENDER] == 'female':\n",
    "        res.drop('governorate_outside_jordan', axis=1, inplace=True)\n",
    "    return res,  data_dct[GENDER]\n",
    "\n",
    "\n",
    "def follow_the_crowd_for_missing_value(model, data): # this is a brute force solution. I beleive there is a better one can be found\n",
    "    \"\"\"This function build the tree structure then select a node for it iff it has missing values \"\"\"\n",
    "    n_nodes = model.tree_.node_count\n",
    "    children_left = model.tree_.children_left\n",
    "    children_right = model.tree_.children_right\n",
    "    feature = model.tree_.feature\n",
    "    name = model.feature_names_in_\n",
    "    threshold = model.tree_.threshold\n",
    "    samples = model.tree_.n_node_samples\n",
    "\n",
    "    node_depth = np.zeros(shape=n_nodes, dtype=np.int64)\n",
    "    is_leaves = np.zeros(shape=n_nodes, dtype=bool)\n",
    "    stack = [(0, 0)]  # start with the root node id (0) and its depth (0)\n",
    "    while len(stack) > 0:\n",
    "        # `pop` ensures each node is only visited once\n",
    "        node_id, depth = stack.pop()\n",
    "        node_depth[node_id] = depth\n",
    "\n",
    "        # If the left and right child of a node is not the same we have a split\n",
    "        # node\n",
    "        is_split_node = children_left[node_id] != children_right[node_id]\n",
    "        # If a split node, append left and right children and depth to `stack`\n",
    "        # so we can loop through them\n",
    "        if is_split_node:\n",
    "            stack.append((children_left[node_id], depth + 1))\n",
    "            stack.append((children_right[node_id], depth + 1))\n",
    "        else:\n",
    "            is_leaves[node_id] = True\n",
    "\n",
    "    # print( \"The binary tree structure has {n} nodes, {l} leaves and has the following tree structure:\\n\".format(n=n_nodes, l=np.sum(is_leaves)))\n",
    "    current_node = 0\n",
    "    for i in range(n_nodes):\n",
    "        # print('current_node is', current_node, end=' ::: ')\n",
    "        if is_leaves[i]:\n",
    "            # print(\"{space}node={node} is a leaf node.\".format(space=node_depth[i] * \"\\t\", node=i))\n",
    "            pass\n",
    "        else:\n",
    "            # print(f\"Check for {name[feature[i]].upper()}\")\n",
    "            if data[name[feature[i]]].values in [np.nan, None]:\n",
    "                if current_node == i:\n",
    "                    # print(f\"{node_depth[i] * '    '}node={i} is a split node for None values: go to node {children_left[i]} if SAMPLES(node {children_left[i]}) {samples[children_left[i]]} >= SAMPLES(node {children_right[i]}) {samples[children_right[i]]} else to node {children_right[i]}.\")\n",
    "                    if samples[children_left[i]] >= samples[children_right[i]]:\n",
    "                        current_node = children_left[i]\n",
    "                    else:\n",
    "                        current_node = children_right[i]\n",
    "            else:\n",
    "                if current_node == i:\n",
    "                    # print(f\"{node_depth[i] * '    '}node={i} is a split node: go to node {children_left[i]} if X[:, {feature[i]} {name[feature[i]]}] <= {threshold[i]} else to node {children_right[i]}.\")\n",
    "                    if data[name[feature[i]]].values <= threshold[i]:\n",
    "                        current_node = children_left[i]\n",
    "                    else:\n",
    "                        current_node = children_right[i]\n",
    "        \n",
    "        if is_leaves[current_node]:\n",
    "            # print(f'Node {current_node} is a leaf node. Its the node where this person will land')\n",
    "            # return current_node, np.argmax(model.tree_.value[current_node])\n",
    "            return current_node, samples[current_node]\n",
    "        \n",
    "    # return current_node, np.argmax(model.tree_.value[current_node])\n",
    "    return current_node, samples[current_node]\n",
    "\n",
    "def surv_tree_predict_node(gender, data=None):\n",
    "    print('Loading Model:', os.path.join(MODELS_OUTPUT_PATH, f'{gender}_surv_tree_model.joblib'))\n",
    "    surv_tree = joblib.load(os.path.join(MODELS_OUTPUT_PATH, f'{gender}_surv_tree_model.joblib'))\n",
    "    # node = np.round(surv_tree.predict(data), 8).astype(object)\n",
    "    \n",
    "    print('Loading Mapper:', os.path.join(MODELS_OUTPUT_PATH, f'{gender}_cluster_node_dict_mapper.joblib'))\n",
    "    node_cluster_mapper = joblib.load(os.path.join(MODELS_OUTPUT_PATH, f'{gender}_cluster_node_dict_mapper.joblib'))\n",
    "    \n",
    "    \n",
    "    print('Loading Mapper Corrector:', os.path.join(MODELS_OUTPUT_PATH, f'{gender}_cluster_node_dict_cmapper.joblib'))\n",
    "    cluster_corrector_mapper = joblib.load(os.path.join(MODELS_OUTPUT_PATH, f'{gender}_cluster_node_dict_cmapper.joblib'))\n",
    "    \n",
    "    if None in data.values or np.nan in data.values:\n",
    "        print('This rec has missing.')\n",
    "        node, samples_c = follow_the_crowd_for_missing_value(surv_tree, data)\n",
    "        print(f\"Follow the crowd lead to node -> {node}, with samples of {samples_c}\")\n",
    "        cluster = node_cluster_mapper[node]\n",
    "        print(f\"Node to Cluster Mapping lead to -> {cluster}\")\n",
    "    else:\n",
    "        print('This rec is complete.')\n",
    "        node = surv_tree.tree_.apply(data.to_numpy().astype('float32'))\n",
    "        print(f\"Using the SurvTree prediction lead to node -> {node}\")\n",
    "        cluster = node_cluster_mapper[node[-1]]\n",
    "        print(f\"Node to Cluster Mapping lead to -> {cluster}\")\n",
    "\n",
    "    # if list(cluster_corrector_mapper.keys()) != list(cluster_corrector_mapper.values()):\n",
    "    cluster = cluster_corrector_mapper[cluster]\n",
    "    print(f\"Correcting the Cluster lead to -> {cluster}\")\n",
    "    \n",
    "    return cluster, node\n",
    "\n",
    "\n",
    "def predict(data_dct, contributers, encoders, onehot, labeled, encoders_outputs_feature,):\n",
    "    data = data_dct.copy()\n",
    "    print(\"Data Recived:\", data)\n",
    "    data = preprocess_recs(\n",
    "        data, \n",
    "        contributers\n",
    "    )\n",
    "\n",
    "    data = encode_new_data(data, contributers, encoders, onehot, labeled)\n",
    "    \n",
    "    data, gen = reorder_cols(data, encoders_outputs_feature)\n",
    "    # display(data)\n",
    "    \n",
    "    return surv_tree_predict_node(\n",
    "        gender='male' if gen == 1 else 'female',\n",
    "        data=data\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "702960cc-d564-4fa4-99b8-9e97498567ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded encoders {'disability': LabelEncoder(), 'education': OneHotEncoder(sparse=False), 'gender': LabelEncoder(), 'governorate': OneHotEncoder(sparse=False)}\n",
      "Data Recived: {'age': 20, 'gender': 'male', 'disability': 'no_disability', 'governorate': None, 'education': 'secondary_or_below', 'experience': 5}\n",
      "After preprocessing: {'governorate': None, 'age': 20, 'experience': 5, 'education': 'secondary_or_below', 'gender': 'male', 'disability': 'no_disability'}\n",
      "Loading Model: .\\runs\\male_surv_tree_model.joblib\n",
      "Loading Mapper: .\\runs\\male_cluster_node_dict_mapper.joblib\n",
      "Loading Mapper Corrector: .\\runs\\male_cluster_node_dict_cmapper.joblib\n",
      "This rec has missing.\n",
      "Follow the crowd lead to node -> 66, with samples of 523\n",
      "Node to Cluster Mapping lead to -> 0\n",
      "Correcting the Cluster lead to -> 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 66)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "API_CONTRIBUTORS = [GOVERNORATE, AGE, EXPERIENCE, EDUCATION, GENDER, DISABILITY]\n",
    "API_ONEHOT_ENCODED = [GOVERNORATE, EDUCATION,]\n",
    "API_LABEL_ENCODED = [GENDER, DISABILITY]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "API_ENCODERS_OUTPUT_ITEMS = [\n",
    "    'experience', 'age', 'disability', \n",
    "    'governorate_ajloun', 'governorate_al_aqaba', 'governorate_al_kirk', 'governorate_al_mafraq', \n",
    "    'governorate_amman', 'governorate_balqa', 'governorate_irbid', 'governorate_jarash', 'governorate_maadaba', \n",
    "    'governorate_maan', 'governorate_outside_jordan', 'governorate_tafileh', 'governorate_zarqa', 'education_bachelor_or_above', \n",
    "    'education_middle_diploma', 'education_secondary_or_below', 'education_vocational_training'\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "API_ENCODERS = {}\n",
    "API_ENCODERS = load_encoders(API_ENCODERS, path=None)\n",
    "\n",
    "# x = {\n",
    "#     GOVERNORATE:'irbed',\n",
    "#     AGE:25,\n",
    "#     EXPERIENCE: 2.586301,\n",
    "#     EDUCATION:'bachelor',\n",
    "#     GENDER:'male',\n",
    "#     # GENDER:'female',\n",
    "#     DISABILITY:'no_disability',\n",
    "# }\n",
    "\n",
    "x = {\n",
    "    AGE:20,\n",
    "    GENDER:'male',\n",
    "    DISABILITY:'no_disability',\n",
    "    GOVERNORATE:None,\n",
    "    EDUCATION:'secondary_or_below',\n",
    "    EXPERIENCE: 5,\n",
    "    # GENDER:'female',\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# After preprocessing: {'governorate': 'amman', 'age': 30, 'experience': 5, 'education': 'secondary_or_below', 'gender': 'male', 'disability': 'no_disability'}\n",
    "\n",
    "predict(x, API_CONTRIBUTORS, API_ENCODERS, API_ONEHOT_ENCODED, API_LABEL_ENCODED, API_ENCODERS_OUTPUT_ITEMS, )\n",
    "# x = preprocess_recs(\n",
    "#     x, \n",
    "#     API_CONTRIBUTORS\n",
    "# )\n",
    "\n",
    "# x = encode_new_data(x, API_CONTRIBUTORS, API_ENCODERS, API_ONEHOT_ENCODED, API_LABEL_ENCODED)\n",
    "\n",
    "# x, gen = reorder_cols(x, API_ENCODERS_OUTPUT_ITEMS)\n",
    "# display(x)\n",
    "\n",
    "# surv_tree_predict_node(gender='male' if gen else 'female', data=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c77734-7709-474d-b041-e3abbf5ecd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5f8af9-256b-4567-a1ae-3dfd369da106",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise # belwo is the section for testing, several changes was made after this one, so it is not valid now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c41272-bea8-449e-9b7d-49b53185b88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('./data/testing.csv', sep=',')\n",
    "\n",
    "# df.columns = [c.lower().strip(' ') for c in df.columns]\n",
    "# df = df[['experience', 'age', 'governorate', 'disability', 'education', 'gender',  'cluster', 'node']]\n",
    "\n",
    "# df.education = df.education.str.replace(' ', '_')\n",
    "# df.governorate = df.governorate.str.replace(' ', '_')\n",
    "# df.disability = df.disability.str.replace(' ', '_')\n",
    "\n",
    "\n",
    "# 0, 1, 2 --> 50\n",
    "# 1, 0, 2 --> 21\n",
    "# 2, 1, 0 --> 25\n",
    "# 0, 2, 1 --> 52\n",
    "# 1, 2, 0 --> 34\n",
    "# 2, 0, 1 --> 14\n",
    "\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'male',\n",
    "#     df.cluster == 'A',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 0\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'male',\n",
    "#     df.cluster == 'B',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 2\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'male',\n",
    "#     df.cluster == 'C',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 0, 1, 2 --> 06\n",
    "# 0, 2, 1 --> 08\n",
    "# 1, 0, 2 --> 71\n",
    "# 1, 2, 0 --> 13\n",
    "# 2, 1, 0 --> 19\n",
    "# 2, 0, 1 --> 80\n",
    "\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'female',\n",
    "#     df.cluster == 'D',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 2\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'female',\n",
    "#     df.cluster == 'E',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 1\n",
    "\n",
    "# con = np.logical_and(\n",
    "#     df.gender == 'female',\n",
    "#     df.cluster == 'F',\n",
    "# )\n",
    "# df.loc[con, 'cluster'] = 0\n",
    "# df\n",
    "\n",
    "\n",
    "# df.columns = ['experience', 'age', 'governorate', 'disability', 'education', 'gender',  'cluster.1']\n",
    "\n",
    "# df.loc[df.education == 'high_school', 'education'] = 'secondary_or_below'\n",
    "# df.loc[df.education == 'bachelor', 'education'] = 'secondary_or_below'\n",
    "# df.loc[df.education == 'deploma', 'education'] = 'middle_diploma'\n",
    "# df.loc[df.education == 'high_diploma', 'education'] = 'middle_diploma'\n",
    "# df.loc[df.education == 'master', 'education'] = 'bachelor_or_above'\n",
    "# df.loc[df.education == 'phd', 'education'] = 'bachelor_or_above'\n",
    "# df.loc[df.education == 'bachelor', 'education'] = 'bachelor_or_above'\n",
    "# df.educations.unique()\n",
    "\n",
    "# df.loc[df.governorate == 'kark', 'governorate'] = 'al_kirk'\n",
    "# df.loc[df.governorate == 'mafraq', 'governorate'] = 'al_mafraq'\n",
    "# df.loc[df.governorate == 'irbed', 'governorate'] = 'irbid'\n",
    "# df.loc[df.governorate == 'jerash', 'governorate'] = 'jarash'\n",
    "# df.loc[df.governorate == 'aqaba', 'governorate'] = 'al_aqaba'\n",
    "# df.loc[df.governorate == 'madaba', 'governorate'] = 'maadaba'\n",
    "# df.loc[df.governorate == 'ajloun', 'governorate'] = 'amman'\n",
    "# df.Governorate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6533cc20-118a-4ea5-ad04-0ae425e0faa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/testing.csv', sep=',')\n",
    "\n",
    "df.columns = [c.lower().strip(' ') for c in df.columns]\n",
    "df = df[['experience', 'age', 'governorate', 'disability', 'education', 'gender',  'cluster', 'node']]\n",
    "\n",
    "df.education = df.education.str.replace(' ', '_')\n",
    "df.governorate = df.governorate.str.replace(' ', '_')\n",
    "df.disability = df.disability.str.replace(' ', '_')\n",
    "\n",
    "\n",
    "con = np.logical_and(\n",
    "    ~df.isnull().any(axis=1),\n",
    "    df.gender == 'female',\n",
    ")\n",
    "\n",
    "full = df[con]\n",
    "# full = df\n",
    "display(full)\n",
    "\n",
    "res_c = []\n",
    "res_n = []\n",
    "counter = 0\n",
    "for row in full.iterrows():\n",
    "    # print(row[-1].to_dict())\n",
    "    correct = row[-1]['cluster']\n",
    "    pred, node = predict(row[-1].to_dict(), API_CONTRIBUTORS, API_ENCODERS, API_ONEHOT_ENCODED, API_LABEL_ENCODED, API_ENCODERS_OUTPUT_ITEMS, )\n",
    "    print(row[0], pred, correct, 'Match' if correct == pred else 'Not Match')\n",
    "    counter += 1  if correct == pred else 0\n",
    "    res_c.append(pred)\n",
    "    res_n.append(node)\n",
    "    # print('-'*50, 'NEXT ROUND', )\n",
    "    \n",
    "full['pred'] = res_c\n",
    "full['pred_node'] = res_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b6aef0c-e9ac-4773-b30a-b95f67826a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy Score:', counter / len(full))\n",
    "display(full.groupby(['cluster', 'node']).count())\n",
    "display(full.groupby(['pred', 'node']).count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1519b455-c8c2-4e65-8f97-44e82e92a837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979e4027-a4e4-4fa4-9501-03eaabc33086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# con = np.logical_and(\n",
    "#     full.node == 31 ,\n",
    "#     full.pred == 2\n",
    "# )\n",
    "\n",
    "# full[con]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f84ce11-2282-491c-ae7c-45ca3b141f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.read_csv('./data/final_outputs.csv')\n",
    "# print(final_df.shape)\n",
    "# res_c = []\n",
    "# res_n = []\n",
    "# counter = 0\n",
    "# for row in final_df.iterrows():\n",
    "#     # print(row[-1].to_dict())\n",
    "#     correct = row[-1]['clusters']\n",
    "#     pred, node = predict(row[-1].to_dict(), API_CONTRIBUTORS, API_ENCODERS, API_ONEHOT_ENCODED, API_LABEL_ENCODED, API_ENCODERS_OUTPUT_ITEMS, )\n",
    "#     print(row[0], pred, correct, 'Match' if correct == pred else 'Not Match')\n",
    "#     counter += 1  if correct == pred else 0\n",
    "#     res_c.append(pred)\n",
    "#     res_n.append(node)\n",
    "#     # print('-'*50, 'NEXT ROUND', )\n",
    "    \n",
    "# final_df['pred'] = res_c\n",
    "# final_df['pred_node'] = res_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decac31a-6d2d-439f-8f75-df2ea491e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Accuracy Score:', counter / len(final_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a13230-bffa-4c10-ad53-9ab92ddd501e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.loc[final_df.pred != final_df.clusters]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec61ac-3cf4-47dc-8c1d-d8e61616c7cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4744aa09-a9d9-4ed0-8e12-ba9b6ae76cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Loading Encoder:', os.path.join(MODELS_OUTPUT_PATH, 'male_surv_tree_nodes_encoder.joblib'))\n",
    "# surv_tree_encoder = joblib.load(os.path.join(MODELS_OUTPUT_PATH, 'male_surv_tree_nodes_encoder.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c0c6a1-fff6-480c-9bf8-6ece0268f5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surv_tree_encoder.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcfcf68-6514-4f06-8a5a-22d3d36dc494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir(surv_tree_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bed5d2c-9d0f-4eb5-a98c-34fd8a178a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# surv_tree_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a1834-89e0-4f98-b815-665bec8526b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed5606-b298-40f5-9200-4bc7d7f28f3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae449d4b-3ac8-4cae-a300-1f73f9653efd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249116fe-1d75-42ae-86a6-03d74ac4d248",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bef7821-8494-4ffb-bae0-24d55057154d",
   "metadata": {},
   "source": [
    "Below, I am building a DecisionTreeClassifier over the results of the statistical analysis and results above. The benefits of this are.\n",
    "\n",
    "1- Less implementation time in the API\n",
    "\n",
    "2- Faster predicting time\n",
    "\n",
    "3- Less componenet to build in the API part\n",
    "\n",
    "4- Less preprocessing steps in the API part\n",
    "\n",
    "5- single and unified referance for modifing the code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847cc223-9070-4ecd-8526-9c7f95cb0afa",
   "metadata": {},
   "source": [
    "Just Have Fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302aae3-950b-4515-aecc-f511acabe4f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5eb71c-d9ec-4832-afa7-48f189d6a5bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c26923-01aa-4a2e-aa5c-34f791afea3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c35122d-8cde-457a-921f-a095e5f74cca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411f2c08-d59f-4bc1-a2d2-3ae0502fbdb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc765d72-989e-48f6-a464-521b9da42511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403e24eb-f232-438c-9309-f8a21e04be92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d781a74b-7523-4e2f-b4e6-396662cb9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736efc90-7a38-4313-98c5-fc4440fb23f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81471f05-0ce2-4a87-8394-7270289419c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.groupby(list(final_df.columns[2:])).size().reset_index().rename(columns={0:'count'}).sort_values('count').iloc[1200:1250]#.drop('count', axis=1)\n",
    "# final_df['age_cat'] = final_df.age.apply(age_code)\n",
    "# final_df['experience_cat'] = final_df.experience.apply(experience_code)\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff1f95-81b8-42e7-95f9-d50c967bf627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = final_df.groupby(list(final_df.columns)[2:]).size().reset_index().rename(columns={0:'count'}).drop('count', axis=1).set_index(API_ATTRIBUTES[2:] + ['age_cat', 'experience_cat']).T.to_dict('records')[0]\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29de1752-e1a0-48cd-98f9-b34fb12dbf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ff = pd.DataFrame()\n",
    "# count = 0\n",
    "# for (governorate, disability, education, gender, age, experience,), cluster in x.items():\n",
    "#     print(experience, age, governorate, disability, education, gender, cluster)\n",
    "#     con = np.logical_and(\n",
    "#             final_df.experience_cat == experience,\n",
    "#             np.logical_and(\n",
    "#                 final_df.age_cat == age,\n",
    "#                 np.logical_and(\n",
    "#                     final_df.governorate == governorate,\n",
    "#                     np.logical_and(\n",
    "#                         final_df.disability == disability,\n",
    "#                         np.logical_and(\n",
    "#                             final_df.education == education,\n",
    "#                             final_df.gender == gender\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#     print(final_df[con].shape[0])\n",
    "#     if final_df[con].shape[0] < 800:\n",
    "#         counts = 800 - final_df[con].shape[0]\n",
    "#         print(counts)\n",
    "#         tmp = generate_fake_dataframe(\n",
    "#             counts, \n",
    "#             'ffcccc', \n",
    "#             col_names = ['experience', 'age', 'disability', 'governorate', 'education', 'gender',], \n",
    "#             intervals = [(0, 25), (15, 59.9), ('disability', 1), ('governorate', 1),  ('education', 1), ('gender', 1)], \n",
    "#             seed = 42,\n",
    "#             cats = [[governorate], [disability], [education], [gender]]\n",
    "#         )\n",
    "#         tmp['clusters'] = cluster\n",
    "#         tmp['age_cat'] = age\n",
    "#         tmp['experience_cat'] = experience\n",
    "        \n",
    "#         tmp = pd.concat([tmp, final_df[con]], ignore_index=True)\n",
    "#     elif final_df[con].shape[0] > 8000:\n",
    "#         tmp = final_df[con].sample(n = 800)\n",
    "#     count += 1\n",
    "#     ff = pd.concat([ff, tmp], ignore_index=True)\n",
    "#     print(f'--------- Round {count} done --------')\n",
    "\n",
    "# ff.to_csv('./data/final_generated_stratified_examples.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8db39d-aa44-499c-9943-a04fa268b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- skewed -- cases appears only 1 time -- data engineering\n",
    "# 2- drop in accuracy -- fine tuning the model and increasing the data\n",
    "# 3- statistical issue for use cases # 1_000_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f792d97-696d-4e81-b632-5e58de2d6463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.DataFrame()\n",
    "# final_df = pd.read_csv('./data/dummy_final_outputs.csv')\n",
    "final_df = pd.read_csv('./data/final_generated_stratified_examples.csv')\n",
    "final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d658059-2df4-4512-a6ab-056ac36bba9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ATTRIBUTES = [EXPERIENCE, AGE, GOVERNORATE, DISABILITY, EDUCATION, GENDER, ] # NODES\n",
    "API_TARGET = [CLUSTER]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18022ac-9294-4abc-9657-de014258ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_CONTRIBUTORS = [DISABILITY, GENDER, GOVERNORATE, EDUCATION, EXPERIENCE, AGE, ]\n",
    "\n",
    "# API_CONTRIBUTORS = [DISABILITY, GENDER, ] # nodes are to drop, clusters are the target\n",
    "# API_CONTRIBUTORS += [f'{GOVERNORATE}_{item}' for item in ['al_kirk', 'zarqa', 'amman', 'irbid', 'al_aqaba', 'jarash', 'balqa', 'maadaba', 'tafileh', 'ajloun', 'maan', 'al_mafraq', 'outside_jordan', ]]\n",
    "# API_CONTRIBUTORS += [f'{EDUCATION}_{item}' for item in ['secondary_or_below', 'vocational_training', 'bachelor_or_above', 'middle_diploma', ]]\n",
    "# API_CONTRIBUTORS += [f'{EXPERIENCE}_{item}' for item in ['0', '1', '5', '10', '15', '20',]]\n",
    "# API_CONTRIBUTORS += [f'{AGE}_{item}' for item in ['20', '30', '40', '50', '60']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fadfd19-00ea-45dd-a415-c34f948797ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(DATA_OUTPUT_PATH)[API_ATTRIBUTES+API_TARGET].convert_dtypes(convert_string=False)\n",
    "# if NODES in df.columns:\n",
    "#     df.drop(NODES, axis=1, inplace=True)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914800d5-c82d-44c9-89d2-78f39714fc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.concat([final_df, df.groupby(list(df.columns)).size().reset_index().rename(columns={0:'count'}).drop('count', axis=1)])\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51675d5-d414-45c8-a5ac-40cee3047473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERSION_DICT = final_df.set_index(API_ATTRIBUTES).T.to_dict('records')[0]\n",
    "# CONVERSION_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c410b9e-3c0e-4e89-8b2b-1dd828e24687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from itertools import cycle\n",
    "# def generate_fake_dataframe(size, cols, col_names = None, intervals = None, seed = None, cats=None):\n",
    "    \n",
    "#     categories_dict = {\n",
    "#         'governorate' : ['ajloun', 'al_aqaba', 'al_kirk', 'al_mafraq', 'amman', 'balqa', 'irbid', 'jarash', 'maadaba', 'maan', 'tafileh', 'zarqa', 'outside_jordan'] if cats is None else cats[0],\n",
    "#         'disability': ['with_disability', 'no_disability',] if cats is None else cats[1],\n",
    "#         'education' : ['bachelor_or_above', 'middle_diploma', 'secondary_or_below', 'vocational_training', ] if cats is None else cats[2],\n",
    "#         'gender' : ['male', 'female', ] if cats is None else cats[3],\n",
    "#     }\n",
    "#     # default_intervals = {\n",
    "#     #     \"c\" : (\"disability\", len(sample.disability.unique()) if sample is not None else  2), \n",
    "#     #     \"c\" : (\"gender\", len(sample.gender.unique()) if sample is not None else  2), \n",
    "#     #     \"c\" : (\"education\", len(sample.education.unique()) if sample is not None else  4), \n",
    "#     #     \"c\" : (\"governorate\", len(sample.governorate.unique()) if sample is not None else  12), \n",
    "#     # }\n",
    "#     default_intervals = {\"i\" : (0,10), \"f\" : (0,100), \"c\" : (\"governorate\", 13), \"d\" : (\"2020-01-01\",\"2020-12-31\")}\n",
    "#     rng = np.random.default_rng(seed)\n",
    "\n",
    "#     first_c = default_intervals[\"c\"][0]\n",
    "#     categories_names = cycle([first_c] + [c for c in categories_dict.keys() if c != first_c])\n",
    "#     default_intervals[\"c\"] = (categories_names, default_intervals[\"c\"][1])\n",
    "    \n",
    "#     if isinstance(col_names, list):\n",
    "#         assert len(col_names) == len(cols), f\"The fake DataFrame should have {len(cols)} columns but col_names is a list with {len(col_names)} elements\"\n",
    "#     elif col_names is None:\n",
    "#         suffix = {\"c\" : \"cat\", \"i\" : \"int\", \"f\" : \"float\", \"d\" : \"date\"}\n",
    "#         col_names = [f\"column_{str(i)}_{suffix.get(col)}\" for i, col in enumerate(cols)]\n",
    "\n",
    "#     if isinstance(intervals,list):\n",
    "#         assert len(intervals) == len(cols), f\"The fake DataFrame should have {len(cols)} columns but intervals is a list with {len(intervals)} elements\"\n",
    "#     else:\n",
    "#         if isinstance(intervals,dict):\n",
    "#             assert len(set(intervals.keys()) - set(default_intervals.keys())) == 0, f\"The intervals parameter has invalid keys\"\n",
    "#             default_intervals.update(intervals)\n",
    "#         intervals = [default_intervals[col] for col in cols]\n",
    "#     df = pd.DataFrame()\n",
    "#     for col, col_name, interval in zip(cols, col_names, intervals):\n",
    "#         if interval is None:\n",
    "#             interval = default_intervals[col]\n",
    "#         assert (len(interval) == 2 and isinstance(interval, tuple)) or isinstance(interval, list), f\"This interval {interval} is neither a tuple of two elements nor a list of strings.\"\n",
    "#         if col in (\"i\",\"f\",\"d\"):\n",
    "#             start, end = interval\n",
    "#         if col == \"i\":\n",
    "#             df[col_name] = rng.integers(start, end, size)\n",
    "#         elif col == \"f\":\n",
    "#             df[col_name] = np.round(rng.uniform(start, end, size), 3)\n",
    "#         elif col == \"c\":\n",
    "#             if isinstance(interval, list):\n",
    "#                 categories = np.array(interval)\n",
    "#             else:\n",
    "#                 cat_family, length = interval\n",
    "#                 if isinstance(cat_family, cycle):\n",
    "#                     cat_family = next(cat_family)\n",
    "#                 print(cat_family)\n",
    "#                 assert cat_family in categories_dict.keys(), f\"There are no samples for category '{cat_family}'. Consider passing a list of samples or use one of the available categories: {categories_dict.keys()}\"\n",
    "#                 print(categories_dict[cat_family], length)\n",
    "#                 categories = rng.choice(categories_dict[cat_family], length, replace = False, shuffle = True)\n",
    "#             df[col_name] = rng.choice(categories, size, shuffle = True)\n",
    "#         elif col == \"d\":\n",
    "#             df[col_name] = rng.choice(pd.date_range(start, end), size)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6b01d6-199a-4008-b302-cd4d95f60b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake_df = generate_fake_dataframe(\n",
    "#     counts, \n",
    "#     'ffcccc', \n",
    "#     col_names = ['experience', 'age', 'disability', 'governorate', 'education', 'gender',], \n",
    "#     intervals = [(0, 25), (15, 59.9), ('disability', 2), ('governorate', 13),  ('education', 4), ('gender', 2)], \n",
    "#     seed = 42,\n",
    "# )\n",
    "# fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa24437e-8760-494b-be56-261c99981215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def experience_code(value):\n",
    "#     if value > 15:\n",
    "#         return 20\n",
    "#     elif value > 10:\n",
    "#         return 15\n",
    "#     elif value > 5:\n",
    "#         return 10\n",
    "#     elif value > 1:\n",
    "#         return 5\n",
    "#     elif value > 0.5:\n",
    "#         return 1\n",
    "#     else:\n",
    "#         return 0\n",
    "    \n",
    "# # - Age:\n",
    "# def age_code(value):\n",
    "#     return (np.round(value / 10) * 10).astype(int)\n",
    "    \n",
    "\n",
    "    \n",
    "# fake_df['categorized_age'] = (np.round(fake_df.age / 10) * 10).astype(int)\n",
    "# fake_df['categorized_experience'] = fake_df.experience.apply(experience_code)\n",
    "# fake_df[CLUSTER] = -1\n",
    "# fake_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd46aa8-bb09-46d5-adea-b5310ade0703",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fill_clusters_based_examples(dct, data):\n",
    "#     count = 0\n",
    "#     for (experience, age, governorate, disability, education, gender), cluster in dct.items():\n",
    "#         print(experience, age, governorate, disability, education, gender, cluster)\n",
    "#         con = np.logical_and(\n",
    "#                 data.categorized_experience == experience,\n",
    "#                 np.logical_and(\n",
    "#                     data.categorized_age == age,\n",
    "#                     np.logical_and(\n",
    "#                         data.governorate == governorate,\n",
    "#                         np.logical_and(\n",
    "#                             data.disability == disability,\n",
    "#                             np.logical_and(\n",
    "#                                 data.education == education,\n",
    "#                                 data.gender == gender\n",
    "#                             )\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#             )\n",
    "#         data.loc[con, CLUSTER] = cluster\n",
    "#         # display(data[con])\n",
    "#         print(data[con].shape)\n",
    "#         count += 1\n",
    "#         print(f'--------- Round {count} done --------')\n",
    "#     return data\n",
    "# tmp = fill_clusters_based_examples(CONVERSION_DICT, fake_df)\n",
    "# tmp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3b4404-625b-49c6-b8ee-48ab9c514f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = tmp.drop(tmp[tmp.clusters == -1].index)\n",
    "# x.drop(['categorized_age', 'categorized_experience'], axis=1, inplace=True)\n",
    "# x.reset_index(drop=True, inplace=True)\n",
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591c1bf1-df5e-49a1-a22b-2c48b90d6afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df = pd.concat([final_df, x], ignore_index=True)\n",
    "# final_df.to_csv('./data/dummy_final_outputs.csv', index=False, encoding='UTF-8')\n",
    "# del fake_df, x, tmp, CONVERSION_DICT, df\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726da0d-d1b2-4c0b-b135-bc36f320b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_df.info())\n",
    "# final_df.groupby('clusters').hist()\n",
    "\n",
    "\n",
    "# # from scipy import stats\n",
    "# # plt.hist(stats.boxcox(final_df.experience + 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9900852e-90bd-4520-8c43-1a31136c3f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONE_HOT_ENCODED_FEATURES = []\n",
    "LABEL_ENCODED_FEATURES = [GENDER, DISABILITY, GOVERNORATE, EDUCATION,] #  AGE, EXPERIENCE, \n",
    "\n",
    "COLUMNS_TO_ENCODE = ONE_HOT_ENCODED_FEATURES + LABEL_ENCODED_FEATURES\n",
    "print(ONE_HOT_ENCODED_FEATURES, LABEL_ENCODED_FEATURES)\n",
    "\n",
    "def encode(data, columns, onehot, labeled, ref={}, store=False):\n",
    "    for col in columns:\n",
    "        if col in labeled:\n",
    "            data[col] = data[col].astype(object)\n",
    "            encoder = LabelEncoder()\n",
    "            data[col] = encoder.fit_transform(data[col])\n",
    "            \n",
    "        elif col in onehot:\n",
    "            data[col] = data[col].astype(object)\n",
    "            encoder = OneHotEncoder(sparse=False)\n",
    "            temp = pd.DataFrame(\n",
    "                encoder.fit_transform(data[[col]]),\n",
    "                columns=list(encoder.get_feature_names_out())\n",
    "            )\n",
    "            data = pd.concat([data, temp], axis=1).drop(col, axis=1)\n",
    "            del temp\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"'{col}' can't be encoded.\")\n",
    "        \n",
    "        ref[col] = encoder\n",
    "        if store:\n",
    "            joblib.dump(encoder, os.path.join(MODELS_OUTPUT_PATH, f'{encoder}_encoder.joblib'))\n",
    "            \n",
    "    return data, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af0edcc-c8f0-42d8-84ef-5c103472966a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_df.age = final_df.age.apply(age_code)\n",
    "# final_df[EXPERIENCE] = final_df[EXPERIENCE].apply(experience_code)\n",
    "# final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c63d93-897a-4a86-91a4-9ea2e67bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dfe, enc = encode(\n",
    "    data=final_df,\n",
    "    columns=COLUMNS_TO_ENCODE,\n",
    "    onehot=ONE_HOT_ENCODED_FEATURES,\n",
    "    labeled=LABEL_ENCODED_FEATURES,\n",
    ")\n",
    "print(enc)\n",
    "final_dfe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cbc22b-0fa0-4a6d-ac48-16a11133faff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_dfe.groupby(CLUSTER).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a6bf95-9812-449d-8988-6404b64359c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = final_dfe[final_dfe.gender == 1]\n",
    "\n",
    "x_train,x_test, y_train, y_test = train_test_split(temp.drop(CLUSTER, axis=1), temp[CLUSTER], test_size=0.15, random_state=42)\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad71751-88f6-4305-b211-a1339f804a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import GridSearchCV, HalvingGridSearchCV\n",
    "\n",
    "\n",
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.kernel_approximation import Nystroem\n",
    "# from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.naive_bayes import CategoricalNB\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from xgboost import XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f0de23-9ad4-41c5-b728-7a71ee71642b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std_slc = StandardScaler()\n",
    "# dec_tree = tree.DecisionTreeClassifier()\n",
    "dec_tree = RandomForestClassifier(n_jobs=-1)\n",
    "# print(dec_tree.get_params().keys())\n",
    "pipe = Pipeline(steps=[\n",
    "    # ('std_slc', std_slc),\n",
    "    ('dec_tree', dec_tree)\n",
    "])\n",
    "\n",
    "\n",
    "# random_state = [None, 0, 1, 42]\n",
    "criterion = ['gini', 'entropy', ]\n",
    "# splitter = ['best', 'random']\n",
    "max_depth = [6, 7, 8, 9, ]\n",
    "min_samples_split = [50, 500, 1500, ]\n",
    "min_samples_leaf = [800, 1300, 1800, ]\n",
    "max_features = ['auto', None]\n",
    "class_weight = [None, 'balanced',]\n",
    "n_estimators =  [25, 100, 150, ]\n",
    "oob_score = [True, False]\n",
    "bootstrap = [True]\n",
    "\n",
    "parameters = dict(\n",
    "    # dec_tree__random_state=random_state,\n",
    "    dec_tree__criterion=criterion,\n",
    "    # dec_tree__splitter=splitter,\n",
    "    dec_tree__max_depth=max_depth,\n",
    "    dec_tree__min_samples_split=min_samples_split,\n",
    "    dec_tree__min_samples_leaf=min_samples_leaf,\n",
    "    dec_tree__max_features=max_features,\n",
    "    dec_tree__class_weight=class_weight,\n",
    "    dec_tree__n_estimators=n_estimators,\n",
    "    dec_tree__oob_score=oob_score,\n",
    "    dec_tree__bootstrap=bootstrap,\n",
    "    # dec_tree__n_jobs=n_jobs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc088fcd-4fe0-4591-aedb-0b3ea96b02e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_GS = HalvingGridSearchCV(\n",
    "    pipe, \n",
    "    parameters, \n",
    "    cv=5, \n",
    "    factor=2, \n",
    "    min_resources='exhaust',\n",
    "    aggressive_elimination=True,\n",
    ")\n",
    "clf_GS.fit(x_train, y_train)\n",
    "print('Best criterion:', clf_GS.best_estimator_.get_params()['dec_tree__criterion'])\n",
    "# print('Best splitter:', clf_GS.best_estimator_.get_params()['dec_tree__splitter'])\n",
    "print('Best max_depth:', clf_GS.best_estimator_.get_params()['dec_tree__max_depth'])\n",
    "print('Best min_samples_split:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_split'])\n",
    "print('Best min_samples_leaf:', clf_GS.best_estimator_.get_params()['dec_tree__min_samples_leaf'])\n",
    "print('Best max_features:', clf_GS.best_estimator_.get_params()['dec_tree__max_features'])\n",
    "print('Best class_weight:', clf_GS.best_estimator_.get_params()['dec_tree__class_weight'])\n",
    "print()\n",
    "print(clf_GS.best_estimator_.get_params()['dec_tree'])\n",
    "pd.DataFrame(clf_GS.cv_results_).tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3388aef0-2486-495b-9594-03e15426776f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d07edb-a775-407f-899c-4827739e55f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce4049c-45fd-4647-a25a-8cea3f46f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DecisionTreeClassifier(\n",
    "#     criterion='entropy', \n",
    "#     max_depth=5, \n",
    "#     min_samples_split= 800,\n",
    "#     min_samples_leaf= 750,\n",
    "#     splitter='best',\n",
    "#     max_features=None,\n",
    "#     class_weight=None,\n",
    "# )\n",
    "\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    max_depth=9, \n",
    "    min_samples_leaf=700, \n",
    "    min_samples_split=50,\n",
    "    n_jobs=-1,\n",
    "    max_features='auto'\n",
    ")\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_train)\n",
    "print(f\"Model Accuracy on TRAINING data:\", accuracy_score(y_train, y_pred))\n",
    "print(classification_report(y_train, y_pred))\n",
    "print('-' * 60)\n",
    "y_pred = model.predict(x_test)\n",
    "print(f\"Model Accuracy on TESTING data:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85408adf-be6a-4bae-948a-cce2b8698957",
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(model, DecisionTreeClassifier):\n",
    "    text_representation = tree.export_text(model)\n",
    "    # print(text_representation)\n",
    "\n",
    "    fig = plt.figure(figsize=(25,20))\n",
    "    _ = tree.plot_tree(\n",
    "        model, \n",
    "        feature_names=final_dfe.drop(CLUSTER, axis=1).columns,  \n",
    "        class_names=['0', '1', '2', ],\n",
    "        filled=True,\n",
    "        # proportion=True,\n",
    "        fontsize=7,\n",
    "        impurity=False,\n",
    "        node_ids=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dd53be-8f0a-45f2-90c9-3465f0fb9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_OUTPUT_PATH)[API_ATTRIBUTES+API_TARGET]\n",
    "# df.experience = df.experience.astype(object)\n",
    "# df.age = df.age.astype(object)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cda5ee-a8b0-4b43-8ff0-5850453bbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    if col in enc.keys():\n",
    "        df[col] = enc[col].transform(df[col])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c90759-7862-4831-82d4-524b5c26d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(df[CLUSTER], model.predict(df.drop([CLUSTER], axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b65642-e43f-400f-82e6-948a6caf9743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predect_node_for_missing_value(api_model, [0, 20, 0, 1, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb437d-a97b-4a4c-9713-028fe976b718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for encoder in API_ENCODERS:\n",
    "#     joblib.dump(API_ENCODERS[encoder], os.path.join(MODELS_OUTPUT_PATH, f'{encoder}_encoder.joblib'))\n",
    "# joblib.dump(api_model, os.path.join(MODELS_OUTPUT_PATH, 'model.joblib'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c81640fb-43ea-4445-b7db-38484f6629ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/testing.csv')\n",
    "df = df[['Experience', 'Age', 'Governorate', 'Disability', 'Educations', 'Gender',  'Cluster.1']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e496ea-684d-4dd5-8e7e-8ac5bdcf4310",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Educations == 'high_school', 'Educations'] = 'secondary_or_below'\n",
    "df.loc[df.Educations == 'bachelor', 'Educations'] = 'secondary_or_below'\n",
    "df.loc[df.Educations == 'deploma', 'Educations'] = 'middle_diploma'\n",
    "df.loc[df.Educations == 'high_diploma', 'Educations'] = 'middle_diploma'\n",
    "df.loc[df.Educations == 'master', 'Educations'] = 'bachelor_or_above'\n",
    "df.loc[df.Educations == 'phd', 'Educations'] = 'bachelor_or_above'\n",
    "df.loc[df.Educations == 'bachelor', 'Educations'] = 'bachelor_or_above'\n",
    "df.Educations.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495f61d4-848f-4553-be28-72a4e871415d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.Governorate == 'kark', 'Governorate'] = 'al_kirk'\n",
    "df.loc[df.Governorate == 'mafraq', 'Governorate'] = 'al_mafraq'\n",
    "df.loc[df.Governorate == 'irbed', 'Governorate'] = 'irbid'\n",
    "df.loc[df.Governorate == 'jerash', 'Governorate'] = 'jarash'\n",
    "df.loc[df.Governorate == 'aqaba', 'Governorate'] = 'al_aqaba'\n",
    "df.loc[df.Governorate == 'madaba', 'Governorate'] = 'maadaba'\n",
    "df.loc[df.Governorate == 'ajloun', 'Governorate'] = 'amman'\n",
    "df.Governorate.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b98900-a9e6-49d8-92ab-723057dc350e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full = df[~df.isnull().any(axis=1)]\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c190ff-c5a0-40b7-b847-1808fbed00af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full.Age = full.Age.apply(age_code).astype(object)\n",
    "# full.Experience = full.Experience.apply(experience_code).astype(object)\n",
    "for col in full.columns:\n",
    "    if col.lower() in enc.keys():\n",
    "        full[col] = enc[col.lower()].fit_transform(full[col])\n",
    "full['Educations'] = enc['education'].transform(full['Educations'])\n",
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7256132-fc80-4097-a7e8-f6cb26947336",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(full[full.Gender == 1]['Cluster.1'], model.predict(full[full.Gender == 1].drop(['Cluster.1'], axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74c53cd-76c7-4a1f-98f9-4643d58d501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full.Age = full.Age.apply(age_code)\n",
    "full.Experience = full.Experience.apply(experience_code)\n",
    "\n",
    "\n",
    "print(accuracy_score(full[full.Gender == 1]['Cluster.1'], model.predict(full[full.Gender == 1].drop(['Cluster.1'], axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069e79fc-1097-4875-8c54-67628ff95b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04327a-c9bd-4013-8ea4-4aa074d3c1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3239595-2e31-422f-8ecc-b4dc97b7b2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# full['categorized_experience']  = full.Experience.apply(experience_code)\n",
    "# full['categorized_age'] = full.Age // 10 * 10\n",
    "# full\n",
    "\n",
    "# def fill_clusters_based_examples(dct, data):\n",
    "#     count = 0\n",
    "#     for (experience, age, governorate, disability, education, gender), cluster in dct.items():\n",
    "#         print(experience, age, governorate, disability, education, gender, cluster)\n",
    "#         con = np.logical_and(\n",
    "#                 data.categorized_experience == experience,\n",
    "#                 np.logical_and(\n",
    "#                     data.categorized_age == age,\n",
    "#                     np.logical_and(\n",
    "#                         data.Governorate == governorate,\n",
    "#                         np.logical_and(\n",
    "#                             data.Disability == disability,\n",
    "#                             np.logical_and(\n",
    "#                                 data.Educations == education,\n",
    "#                                 data.Gender == gender\n",
    "#                             )\n",
    "#                         )\n",
    "#                     )\n",
    "#                 )\n",
    "#             )\n",
    "#         data.loc[con, CLUSTER] = cluster\n",
    "#         # display(data[con])\n",
    "#         print(data[con].shape)\n",
    "#         count += 1\n",
    "#         print(f'--------- Round {count} done --------')\n",
    "#     return data\n",
    "# fill_clusters_based_examples(CONVERSION_DICT, full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f32506-1543-4ad3-b71d-d1297db45148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1278\n",
    "# 12M ~ 1M\n",
    "# 2 * 2 * 4 * 13 * 6 * 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b525a3-7dca-476a-80ea-37f8bcab5d25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e22622-db95-4c79-b3da-a6c913171115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f8fc39-eba8-4616-9097-ac7f45e0dd24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8378f1e-607a-4578-8af2-5e53e43ff36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
